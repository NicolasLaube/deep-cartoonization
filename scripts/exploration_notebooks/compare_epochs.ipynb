{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# To compare between epochs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "TO_COMPARE = [5, 10, 20, 30, 40, 50, 60] # bs\n",
                "\n",
                "RUN_ID = \"2022_03_28-02_02_28\"\n",
                "\n",
                "NB_IMAGES = 20\n",
                "\n",
                "BATCH_SIZE = 5\n",
                "\n",
                "WIDTH = 8\n",
                "HEIGHT = 8\n",
                "\n",
                "LOSS_UNTIL_EPOCH = TO_COMPARE[-1]\n",
                "WINDOW_SIZE = 101"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_name(epoch: int) -> str:\n",
                "    return f\"{RUN_ID} on {epoch}\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd ../.."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import csv\n",
                "import json\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from ast import literal_eval\n",
                "from math import ceil\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from scipy.signal import savgol_filter\n",
                "\n",
                "from scripts import config\n",
                "from scripts.tools.get_name import get_gen_name, get_model_img_name\n",
                "from scripts.tools.type_dict.csv_to_object import architecture_dict, crop_mode_dict, ratio_filter_dict\n",
                "from src.pipelines.cartoonizer import Cartoonizer\n",
                "from src import models, dataset\n",
                "\n",
                "sns.set()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_cartoonizer(df_runs, epoch):\n",
                "    run = df_runs.loc[df_runs['run_id'] == RUN_ID].iloc[0]\n",
                "    gen_path = os.path.join(\n",
                "        config.WEIGHTS_FOLDER,\n",
                "        run[\"run_id\"],get_gen_name(epoch)\n",
                "        \n",
                "    )\n",
                "\n",
                "    pictures_dataset_parameters = dataset.PicturesDatasetParameters(\n",
                "        new_size=literal_eval(run[\"picture_dataset_new_size\"]),\n",
                "        crop_mode=crop_mode_dict[run[\"picture_dataset_crop_mode\"]],\n",
                "        ratio_filter_mode=ratio_filter_dict[run[\"picture_dataset_ratio_filter_mode\"]],\n",
                "        nb_images=NB_IMAGES,\n",
                "    )\n",
                "\n",
                "    cartoonizer = Cartoonizer(\n",
                "        infering_parameters=models.InferingParams(batch_size=BATCH_SIZE),\n",
                "        architecture=architecture_dict[run[\"cartoon_gan_architecture\"]],\n",
                "        architecture_params=models.ArchitectureParamsNULL(),\n",
                "        pictures_dataset_parameters=pictures_dataset_parameters,\n",
                "        gen_path=gen_path,\n",
                "    )\n",
                "\n",
                "    return get_name(epoch), cartoonizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_picture_path(epoch):\n",
                "    pictures_path = os.path.join(config.LOGS_FOLDER, RUN_ID, \"pictures\")\n",
                "    epoch_pictures_path = os.path.join(\n",
                "        pictures_path, f\"epoch_{epoch}\"\n",
                "    )\n",
                "    return {\"name\": get_name(epoch), \"path\": epoch_pictures_path}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Losses on training set\n",
                "i = 1\n",
                "X = []\n",
                "Y_gen = []\n",
                "Y_disc = []\n",
                "\n",
                "folder_path = os.path.join(config.LOGS_FOLDER, RUN_ID, \"losses\")\n",
                "file_names = list(filter(lambda name : name[-3:] == \"txt\" and name != \"train_validation.txt\", os.listdir(folder_path)))\n",
                "file_names.sort(key=lambda name : int(name.split(\"_\")[1].split(\".\")[0]))\n",
                "for file_name in file_names:\n",
                "    if int(file_name.split(\"_\")[1].split(\".\")[0]) > LOSS_UNTIL_EPOCH:\n",
                "        break\n",
                "    with open(os.path.join(folder_path, file_name)) as csv_file:\n",
                "        csv_reader = csv.reader(csv_file)\n",
                "        new_X_values = []\n",
                "        for i, row in enumerate(csv_reader):\n",
                "            losses = json.loads(row[1].replace(\"\\'\", \"\\\"\"))\n",
                "            new_X_values.append(i)\n",
                "            Y_disc.append(losses[\"disc_loss\"])\n",
                "            Y_gen.append(losses[\"gen_loss\"])\n",
                "        new_X_values = np.array(new_X_values)/len(new_X_values) + int(file_name.split(\"_\")[1].split(\".\")[0]) - 1\n",
                "        X.extend(list(new_X_values))\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(X, savgol_filter(Y_gen, WINDOW_SIZE, 3))\n",
                "plt.title(\"Generator loss on training set\", fontsize=18, fontweight='bold')\n",
                "plt.xlabel(\"Epoch\", fontsize=14)\n",
                "plt.ylabel(\"Loss\", fontsize=14)\n",
                "plt.show()\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(X, savgol_filter(Y_disc, WINDOW_SIZE, 3))\n",
                "plt.title(\"Disciminator loss on training set\", fontsize=18, fontweight='bold')\n",
                "plt.xlabel(\"Epoch\", fontsize=14)\n",
                "plt.ylabel(\"Loss\", fontsize=14)\n",
                "plt.show()\n",
                "\n",
                "# Then show the losses on validation set\n",
                "with open(os.path.join(config.LOGS_FOLDER, RUN_ID, \"losses\", \"train_validation.txt\"), encoding=\"utf-8\") as file:\n",
                "    csv_reader = csv.reader(file)\n",
                "    X = list(range(1, LOSS_UNTIL_EPOCH+1))\n",
                "    Y_disc = []\n",
                "    Y_gen = []\n",
                "    for i, row in enumerate(csv_reader):\n",
                "        if i >= LOSS_UNTIL_EPOCH:\n",
                "            break\n",
                "        losses = json.loads(row[1].replace(\"\\'\", \"\\\"\"))\n",
                "        Y_disc.append(losses[\"disc_loss\"])\n",
                "        Y_gen.append(losses[\"gen_loss\"])\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(X, Y_gen)\n",
                "plt.title(\"Generator loss on validation set\", fontsize=18, fontweight='bold')\n",
                "plt.xlabel(\"Epoch\", fontsize=14)\n",
                "plt.ylabel(\"Loss\", fontsize=14)\n",
                "plt.show()\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(X, Y_disc)\n",
                "plt.title(\"Disciminator loss on validation set\", fontsize=18, fontweight='bold')\n",
                "plt.xlabel(\"Epoch\", fontsize=14)\n",
                "plt.ylabel(\"Loss\", fontsize=14)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_runs = pd.read_csv(config.REMOTE_PARAMS_PATH, index_col=0)\n",
                "all_paths = {epoch: get_picture_path(epoch) for epoch in TO_COMPARE}\n",
                "\n",
                "max_epoch = df_runs.loc[df_runs['run_id'] == RUN_ID].iloc[0][\"epochs_trained_nb\"]\n",
                "\n",
                "for i in range(NB_IMAGES):\n",
                "    nb_epochs = len(TO_COMPARE)\n",
                "    cols = 2\n",
                "    rows = ceil((nb_epochs+1)/cols)\n",
                "    fig = plt.figure(figsize=(WIDTH*cols, HEIGHT*rows))\n",
                "    picture = plt.imread(os.path.join(all_paths[TO_COMPARE[0]]['path'], get_model_img_name(i, \"picture\")))\n",
                "    ax = fig.add_subplot(rows, cols, 1)\n",
                "    ax.axis(\"off\")\n",
                "    ax.imshow(picture)\n",
                "    plt.title(\"Original picture\")\n",
                "    for j in range(len(TO_COMPARE)):\n",
                "        epoch = min(TO_COMPARE[j], max_epoch)\n",
                "        cartoon = plt.imread(os.path.join(all_paths[epoch]['path'], get_model_img_name(i, \"cartoon\")))\n",
                "        ax = fig.add_subplot(rows, cols, j+2)\n",
                "        ax.imshow(cartoon)\n",
                "        plt.title(all_paths[epoch]['name'])\n",
                "        ax.axis(\"off\")\n",
                "        if epoch == max_epoch:\n",
                "            break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "95d434c15d7c1f28b268fe54cfe54716ddab65e34521285ad9829a57e3094f9f"
        },
        "kernelspec": {
            "display_name": "Python 3.9.9 ('deepl')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
