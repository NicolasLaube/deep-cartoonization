{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# To compare between models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TO_COMPARE = [\"2022_03_27-20_51_13\", \"2022_03_27-20_51_29\", \"2022_03_27-20_51_43\"] # lr from scratch\n",
                "# TO_COMPARE = [\"2022_03_28-02_01_58\", \"2022_03_28-02_02_43\", \"2022_03_28-02_02_38\", \"2022_03_28-02_02_28\", \"2022_03_28-18_15_16\"] # lr\n",
                "# TO_COMPARE = [\"2022_03_28-18_15_38\",\"2022_03_28-18_23_16\",\"2022_03_29-04_12_27\",\"2022_03_29-04_14_51\"] # bs\n",
                "# TO_COMPARE = [\"2022_03_28-02_02_38\", \"2022_03_29-21_05_24\", \"2022_03_29-21_05_31\"] # crop\n",
                "TO_COMPARE = [\"2022_03_31-18_37_59_gpK\",\"2022_04_04-18_27_57_veL\",\"2022_04_10-00_03_33_Iea\",\"2022_04_09-16_02_23_CES\",\"2022_04_10-00_00_30_jax\",\"2022_04_04-03_19_26_QAj\",\"2022_03_31-18_38_39_AqQ\",\"2022_03_31-18_56_57_xfY\",\"2022_03_28-02_02_38\",\"2022_04_01-04_25_45_DEW\",\"2022_04_01-18_56_08_GUY\"] # content loss\n",
                "# TO_COMPARE = [\"2022_03_28-02_02_38\", \"2022_04_04-03_03_34_FTX\", \"2022_04_04-03_03_07_KVM\", \"2022_04_04-02_53_39_YpC\"] # blur filter\n",
                "\n",
                "COMPARE_ON_EPOCH = 50\n",
                "\n",
                "WITH_ORIGINAL_IMAGE = True\n",
                "\n",
                "NB_IMAGES = 50\n",
                "\n",
                "BATCH_SIZE = 5\n",
                "\n",
                "WIDTH = 8\n",
                "HEIGHT = 8\n",
                "\n",
                "WINDOW_SIZE = 101"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_name(row):\n",
                "    epoch_nb = min(COMPARE_ON_EPOCH, row[\"epochs_trained_nb\"])\n",
                "    # return f\"{row['run_id']} on {epoch_nb} with lr {row['training_gen_lr']}\" # lr\n",
                "    # return f\"{row['run_id']} on {epoch_nb} with batch size {row['training_batch_size']}\" # bs\n",
                "    # return f\"{row['run_id']} on {epoch_nb} with crop mode {row['cartoon_dataset_crop_mode']}\" # crop\n",
                "    return f\"{row['run_id']} on {epoch_nb} with content loss {row['training_weight_generator_content_loss']}\" # content loss\n",
                "    # return f\"{row['run_id']} on {epoch_nb} with smoothing kernel {row['picture_dataset_smoothing_kernel_size']}\" # smoothing kernel"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# def get_name(row):\n",
                "#     return f\"learning rate = {row['training_gen_lr']}\" # lr\n",
                "#     return f\"batch size = {row['training_batch_size']}\" # bs\n",
                "#     return f\"crop mode {row['cartoon_dataset_crop_mode']}\" # crop\n",
                "#     return f\"content loss weight = {row['training_weight_generator_content_loss']}\" # content loss\n",
                "#     return f\"smoothing kernel size = {row['picture_dataset_smoothing_kernel_size']}\" # smoothing kernel"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd ../.."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import csv\n",
                "import json\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from ast import literal_eval\n",
                "from math import ceil\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from scipy.signal import savgol_filter\n",
                "\n",
                "from scripts import config\n",
                "from scripts.tools.get_name import get_gen_name, get_model_img_name\n",
                "from scripts.tools.type_dict.csv_to_object import architecture_dict, crop_mode_dict, ratio_filter_dict\n",
                "from src.pipelines.cartoonizer import Cartoonizer\n",
                "from src import models, dataset\n",
                "\n",
                "sns.set()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_cartoonizer(df_runs, run_id):\n",
                "    run = df_runs.loc[df_runs['run_id'] == run_id].iloc[0]\n",
                "    epoch_nb = min(COMPARE_ON_EPOCH, run[\"epochs_trained_nb\"])\n",
                "    gen_path = os.path.join(\n",
                "        config.WEIGHTS_FOLDER,\n",
                "        run[\"run_id\"],\n",
                "        get_gen_name(epoch_nb),\n",
                "    )\n",
                "\n",
                "    pictures_dataset_parameters = dataset.PicturesDatasetParameters(\n",
                "        new_size=literal_eval(run[\"picture_dataset_new_size\"]),\n",
                "        crop_mode=crop_mode_dict[run[\"picture_dataset_crop_mode\"]],\n",
                "        ratio_filter_mode=ratio_filter_dict[run[\"picture_dataset_ratio_filter_mode\"]],\n",
                "        nb_images=NB_IMAGES,\n",
                "    )\n",
                "\n",
                "    cartoonizer = Cartoonizer(\n",
                "        infering_parameters=models.InferingParams(batch_size=BATCH_SIZE),\n",
                "        architecture=architecture_dict[run[\"cartoon_gan_architecture\"]],\n",
                "        architecture_params=models.ArchitectureParamsNULL(),\n",
                "        pictures_dataset_parameters=pictures_dataset_parameters,\n",
                "        gen_path=gen_path,\n",
                "    )\n",
                "\n",
                "    return get_name(run), cartoonizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_pictures_path(df_runs, run_id):\n",
                "    run = df_runs.loc[df_runs['run_id'] == run_id].iloc[0]\n",
                "    epoch_nb = min(COMPARE_ON_EPOCH, run[\"epochs_trained_nb\"])\n",
                "    pictures_path = os.path.join(config.LOGS_FOLDER, run_id, \"pictures\")\n",
                "    epoch_pictures_path = os.path.join(\n",
                "        pictures_path, f\"epoch_{epoch_nb}\"\n",
                "    )\n",
                "    return {\"name\": get_name(run), \"path\": epoch_pictures_path}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_runs = pd.read_csv(config.REMOTE_PARAMS_PATH, index_col=0)\n",
                "\n",
                "# Losses on training set\n",
                "Y_gen = {}\n",
                "Y_disc = {}\n",
                "for run_id in TO_COMPARE:\n",
                "    folder_path = os.path.join(config.LOGS_FOLDER, run_id, \"losses\")\n",
                "    file_names = list(filter(lambda name : name[-3:] == \"txt\" and name != \"train_validation.txt\", os.listdir(folder_path)))\n",
                "    file_names.sort(key=lambda name : int(name.split(\"_\")[1].split(\".\")[0]))\n",
                "    run_name = get_name(df_runs.loc[df_runs['run_id'] == run_id].iloc[0])\n",
                "    Y_gen[run_name] = {\"X\": [], \"Y\": []}\n",
                "    Y_disc[run_name] = {\"X\": [], \"Y\": []}\n",
                "    for file_name in file_names:\n",
                "        if int(file_name.split(\"_\")[1].split(\".\")[0]) > COMPARE_ON_EPOCH:\n",
                "            break\n",
                "        with open(os.path.join(folder_path, file_name)) as csv_file:\n",
                "            csv_reader = csv.reader(csv_file)\n",
                "            new_X_values = []\n",
                "            for i, row in enumerate(csv_reader):\n",
                "                try:\n",
                "                    losses = json.loads(row[1].replace(\"\\'\", \"\\\"\"))\n",
                "                except:\n",
                "                    continue\n",
                "                Y_disc[run_name][\"Y\"].append(losses[\"disc_loss\"])\n",
                "                Y_gen[run_name][\"Y\"].append(losses[\"gen_loss\"])\n",
                "                new_X_values.append(i)\n",
                "            new_X_values = np.array(new_X_values)/len(new_X_values) + int(file_name.split(\"_\")[1].split(\".\")[0]) - 1\n",
                "            Y_gen[run_name][\"X\"].extend(list(new_X_values))\n",
                "            Y_disc[run_name][\"X\"].extend(list(new_X_values))\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "for name, XY in Y_gen.items():\n",
                "    plt.plot(XY[\"X\"], savgol_filter(XY[\"Y\"], WINDOW_SIZE, 3), label=name)\n",
                "plt.title(\"Generator loss on training set\", fontsize=18, fontweight='bold')\n",
                "plt.xlabel(\"Epoch\", fontsize=14)\n",
                "plt.ylabel(\"Loss\", fontsize=14)\n",
                "plt.legend(loc='upper right')\n",
                "plt.show()\n",
                "plt.figure(figsize=(12, 6))\n",
                "for name, XY in Y_disc.items():\n",
                "    plt.plot(XY[\"X\"], savgol_filter(XY[\"Y\"], WINDOW_SIZE, 3), label=name)\n",
                "plt.title(\"Disciminator loss on training set\", fontsize=18, fontweight='bold')\n",
                "plt.xlabel(\"Epoch\", fontsize=14)\n",
                "plt.ylabel(\"Loss\", fontsize=14)\n",
                "plt.legend(loc='upper right')\n",
                "plt.show()\n",
                "\n",
                "# Then show the losses on validation set\n",
                "Y_gen = {}\n",
                "Y_disc = {}\n",
                "for run_id in TO_COMPARE:\n",
                "    file_path = os.path.join(config.LOGS_FOLDER, run_id, \"losses\", \"train_validation.txt\")\n",
                "    run_name = get_name(df_runs.loc[df_runs['run_id'] == run_id].iloc[0])\n",
                "    Y_gen[run_name] = []\n",
                "    Y_disc[run_name] = []\n",
                "    with open(file_path, encoding=\"utf-8\") as file:\n",
                "        csv_reader = csv.reader(file)\n",
                "        for i, row in enumerate(csv_reader):\n",
                "            if i >= COMPARE_ON_EPOCH:\n",
                "                break\n",
                "            losses = json.loads(row[1].replace(\"\\'\", \"\\\"\"))\n",
                "            Y_disc[run_name].append(losses[\"disc_loss\"])\n",
                "            Y_gen[run_name].append(losses[\"gen_loss\"])\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "for name, Y in Y_gen.items():\n",
                "    plt.plot(range(1, len(Y)+1), Y, label=name)\n",
                "plt.title(\"Generator loss on validation set\", fontsize=18, fontweight='bold')\n",
                "plt.xlabel(\"Epoch\", fontsize=14)\n",
                "plt.ylabel(\"Loss\", fontsize=14)\n",
                "plt.legend(loc='upper right')\n",
                "plt.show()\n",
                "plt.figure(figsize=(12, 6))\n",
                "for name, Y in Y_disc.items():\n",
                "    plt.plot(range(1, len(Y)+1), Y, label=name)\n",
                "plt.title(\"Disciminator loss on validation set\", fontsize=18, fontweight='bold')\n",
                "plt.xlabel(\"Epoch\", fontsize=14)\n",
                "plt.ylabel(\"Loss\", fontsize=14)\n",
                "plt.legend(loc='upper right')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_runs = pd.read_csv(config.REMOTE_PARAMS_PATH, index_col=0)\n",
                "all_paths = {run_id: get_pictures_path(df_runs, run_id) for run_id in TO_COMPARE}\n",
                "\n",
                "for i in range(NB_IMAGES):\n",
                "    nb_models = len(TO_COMPARE)\n",
                "    cols = 2\n",
                "    rows = ceil((nb_models+1)/cols) if WITH_ORIGINAL_IMAGE else ceil((nb_models)/cols)\n",
                "    fig = plt.figure(figsize=(WIDTH*cols, HEIGHT*rows))\n",
                "    to_add = 1\n",
                "    if WITH_ORIGINAL_IMAGE:\n",
                "        picture = plt.imread(os.path.join(all_paths[TO_COMPARE[0]]['path'], get_model_img_name(i, \"picture\")))\n",
                "        ax = fig.add_subplot(rows, cols, 1)\n",
                "        ax.axis(\"off\")\n",
                "        ax.imshow(picture)\n",
                "        plt.title(\"Original picture\")\n",
                "        to_add = 2\n",
                "    for j in range(len(TO_COMPARE)):\n",
                "        run_id = TO_COMPARE[j]\n",
                "        cartoon = plt.imread(os.path.join(all_paths[run_id]['path'], get_model_img_name(i, \"cartoon\")))\n",
                "        ax = fig.add_subplot(rows, cols, j+to_add)\n",
                "        ax.imshow(cartoon)\n",
                "        plt.title(all_paths[run_id]['name'])\n",
                "        ax.axis(\"off\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "95d434c15d7c1f28b268fe54cfe54716ddab65e34521285ad9829a57e3094f9f"
        },
        "kernelspec": {
            "display_name": "Python 3.9.9 ('deepl')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
