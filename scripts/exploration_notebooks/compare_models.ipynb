{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# To compare between models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TO_COMPARE = [\"2022_03_27-20_51_13\", \"2022_03_27-20_51_29\", \"2022_03_27-20_51_43\"] # lr from scratch\n",
                "# TO_COMPARE = [\"2022_03_28-02_01_58\",\"2022_03_28-02_02_28\",\"2022_03_28-02_02_38\",\"2022_03_28-02_02_43\",\"2022_03_28-18_15_16\"] # lr\n",
                "# TO_COMPARE = [\"2022_03_28-18_15_38\",\"2022_03_28-18_23_16\",\"2022_03_29-04_12_27\",\"2022_03_29-04_14_51\"] # bs\n",
                "# TO_COMPARE = [\"2022_03_28-02_02_38\", \"2022_03_29-21_05_24\", \"2022_03_29-21_05_31\"] # crop\n",
                "TO_COMPARE = [\"2022_03_31-18_37_59_gpK\",\"2022_03_31-18_38_39_AqQ\",\"2022_03_31-18_56_57_xfY\",\"2022_03_28-02_02_38\",\"2022_04_01-04_25_45_DEW\",\"2022_04_01-18_56_08_GUY\"]\n",
                "\n",
                "COMPARE_ON_EPOCH = 40\n",
                "\n",
                "NB_IMAGES = 20\n",
                "\n",
                "BATCH_SIZE = 5\n",
                "\n",
                "WIDTH = 8\n",
                "HEIGHT = 8"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_name(row):\n",
                "    epoch_nb = min(COMPARE_ON_EPOCH, row[\"epochs_trained_nb\"])\n",
                "    # return f\"{row['run_id']} on {epoch_nb} with lr {row['training_gen_lr']}\" # lr\n",
                "    # return f\"{row['run_id']} on {epoch_nb} with batch size {row['training_batch_size']}\" # bs\n",
                "    # return f\"{row['run_id']} on {epoch_nb} with crop mode {row['cartoon_dataset_crop_mode']}\" # crop\n",
                "    return f\"{row['run_id']} on {epoch_nb} with content loss {row['training_weight_generator_content_loss']}\" # content loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd ../.."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "from ast import literal_eval\n",
                "from math import ceil\n",
                "\n",
                "from scripts import config\n",
                "from scripts.tools.get_name import get_gen_name, get_model_img_name\n",
                "from scripts.tools.type_dict.csv_to_object import architecture_dict, crop_mode_dict, ratio_filter_dict\n",
                "from src.pipelines.cartoonizer import Cartoonizer\n",
                "from src import models, dataset\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_cartoonizer(df_runs, run_id):\n",
                "    run = df_runs.loc[df_runs['run_id'] == run_id].iloc[0]\n",
                "    epoch_nb = min(COMPARE_ON_EPOCH, run[\"epochs_trained_nb\"])\n",
                "    gen_path = os.path.join(\n",
                "        config.WEIGHTS_FOLDER,\n",
                "        run[\"run_id\"],\n",
                "        get_gen_name(epoch_nb),\n",
                "    )\n",
                "\n",
                "    pictures_dataset_parameters = dataset.PicturesDatasetParameters(\n",
                "        new_size=literal_eval(run[\"picture_dataset_new_size\"]),\n",
                "        crop_mode=crop_mode_dict[run[\"picture_dataset_crop_mode\"]],\n",
                "        ratio_filter_mode=ratio_filter_dict[run[\"picture_dataset_ratio_filter_mode\"]],\n",
                "        nb_images=NB_IMAGES,\n",
                "    )\n",
                "\n",
                "    cartoonizer = Cartoonizer(\n",
                "        infering_parameters=models.InferingParams(batch_size=BATCH_SIZE),\n",
                "        architecture=architecture_dict[run[\"cartoon_gan_architecture\"]],\n",
                "        architecture_params=models.ArchitectureParamsNULL(),\n",
                "        pictures_dataset_parameters=pictures_dataset_parameters,\n",
                "        gen_path=gen_path,\n",
                "    )\n",
                "\n",
                "    return get_name(run), cartoonizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_path(df_runs, run_id):\n",
                "    run = df_runs.loc[df_runs['run_id'] == run_id].iloc[0]\n",
                "    epoch_nb = min(COMPARE_ON_EPOCH, run[\"epochs_trained_nb\"])\n",
                "    pictures_path = os.path.join(config.LOGS_FOLDER, run_id, \"pictures\")\n",
                "    epoch_pictures_path = os.path.join(\n",
                "        pictures_path, f\"epoch_{epoch_nb}\"\n",
                "    )\n",
                "    return {\"name\": get_name(run), \"path\": epoch_pictures_path}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_runs = pd.read_csv(config.REMOTE_PARAMS_PATH, index_col=0)\n",
                "all_paths = {run_id: get_path(df_runs, run_id) for run_id in TO_COMPARE}\n",
                "\n",
                "for i in range(NB_IMAGES):\n",
                "    nb_models = len(TO_COMPARE)\n",
                "    cols = 2\n",
                "    rows = ceil((nb_models+1)/cols)\n",
                "    fig = plt.figure(figsize=(WIDTH*cols, HEIGHT*rows))\n",
                "    picture = plt.imread(os.path.join(all_paths[TO_COMPARE[0]]['path'], get_model_img_name(i, \"picture\")))\n",
                "    ax = fig.add_subplot(rows, cols, 1)\n",
                "    ax.axis(\"off\")\n",
                "    ax.imshow(picture)\n",
                "    plt.title(\"Original picture\")\n",
                "    for j in range(len(TO_COMPARE)):\n",
                "        run_id = TO_COMPARE[j]\n",
                "        cartoon = plt.imread(os.path.join(all_paths[run_id]['path'], get_model_img_name(i, \"cartoon\")))\n",
                "        ax = fig.add_subplot(rows, cols, j+2)\n",
                "        ax.imshow(cartoon)\n",
                "        plt.title(all_paths[run_id]['name'])\n",
                "        ax.axis(\"off\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "95d434c15d7c1f28b268fe54cfe54716ddab65e34521285ad9829a57e3094f9f"
        },
        "kernelspec": {
            "display_name": "Python 3.9.9 ('deepl')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
