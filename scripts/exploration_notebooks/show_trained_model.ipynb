{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show results of a specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"2022_03_27-20_51_13\"\n",
    "WIDTH = 8\n",
    "HEIGHT = 8\n",
    "\n",
    "LOSS_UNTIL_EPOCH = 20\n",
    "WINDOW_SIZE = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from scripts import config\n",
    "from scripts.tools.get_name import get_model_img_name\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(model_id):\n",
    "    df_runs = pd.read_csv(config.REMOTE_PARAMS_PATH, index_col=0)\n",
    "    df_result = df_runs.loc[df_runs['run_id'] == model_id]\n",
    "    run = df_result.iloc[0]\n",
    "\n",
    "    pictures_path = os.path.join(config.LOGS_FOLDER, run[\"run_id\"], \"pictures\")\n",
    "    epoch_pictures_path = os.path.join(\n",
    "        pictures_path, f\"epoch_{run['epochs_trained_nb']}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"\"\"Model {run['run_id']} with epoch {run['epochs_trained_nb']}:\n",
    "    - Architecture: {run['cartoon_gan_architecture']}\n",
    "    - Pictures size: {run['picture_dataset_new_size']}\n",
    "    - Learning rate: {run['training_gen_lr']}\n",
    "    - Crop mode: {run['picture_dataset_crop_mode']}\n",
    "    - Init generator path: {run['init_gen_path']}\n",
    "\n",
    "    With losses:\n",
    "    - Generator loss: {run['train_gen_loss']}\n",
    "    - Discriminator loss: {run['train_disc_loss']}\"\"\"\n",
    "    )\n",
    "\n",
    "    # Losses on training set\n",
    "    i = 1\n",
    "    X = []\n",
    "    Y_gen = []\n",
    "    Y_disc = []\n",
    "    folder_path = os.path.join(config.LOGS_FOLDER, run['run_id'], \"losses\")\n",
    "    file_names = list(filter(lambda name : name[-3:] == \"txt\" and name != \"train_validation.txt\", os.listdir(folder_path)))\n",
    "    file_names.sort(key=lambda name : int(name.split(\"_\")[1].split(\".\")[0]))\n",
    "    for file_name in file_names:\n",
    "        if int(file_name.split(\"_\")[1].split(\".\")[0]) > LOSS_UNTIL_EPOCH:\n",
    "            break\n",
    "        with open(os.path.join(folder_path, file_name)) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            new_X_values = []\n",
    "            for row in csv_reader:\n",
    "                losses = json.loads(row[1].replace(\"\\'\", \"\\\"\"))\n",
    "                Y_disc.append(losses[\"disc_loss\"])\n",
    "                Y_gen.append(losses[\"gen_loss\"])\n",
    "                new_X_values.append(i)\n",
    "                i += 1\n",
    "            new_X_values = np.array(new_X_values)/len(new_X_values) + int(file_name.split(\"_\")[1].split(\".\")[0]) - 1\n",
    "            X.extend(list(new_X_values))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X, savgol_filter(Y_gen, WINDOW_SIZE, 3))\n",
    "    plt.title(\"Generator loss on training set\", fontsize=18, fontweight='bold')\n",
    "    plt.xlabel(\"Epoch\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X, savgol_filter(Y_disc, WINDOW_SIZE, 3))\n",
    "    plt.title(\"Disciminator loss on training set\", fontsize=18, fontweight='bold')\n",
    "    plt.xlabel(\"Epoch\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    # Then show the losses on validation set\n",
    "    with open(os.path.join(config.LOGS_FOLDER, run['run_id'], \"losses\", \"train_validation.txt\"), encoding=\"utf-8\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        X = list(range(1, LOSS_UNTIL_EPOCH+1))\n",
    "        Y_disc = []\n",
    "        Y_gen = []\n",
    "        for i, row in enumerate(csv_reader):\n",
    "            if i >= LOSS_UNTIL_EPOCH:\n",
    "                break\n",
    "            losses = json.loads(row[1].replace(\"\\'\", \"\\\"\"))\n",
    "            Y_disc.append(losses[\"disc_loss\"])\n",
    "            Y_gen.append(losses[\"gen_loss\"])\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X, Y_gen)\n",
    "    plt.title(\"Generator loss on validation set\", fontsize=18, fontweight='bold')\n",
    "    plt.xlabel(\"Epoch\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X, Y_disc)\n",
    "    plt.title(\"Disciminator loss on validation set\", fontsize=18, fontweight='bold')\n",
    "    plt.xlabel(\"Epoch\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    # Finally show cartoonized pictures\n",
    "    columns = 2\n",
    "    nb_pictures = len(os.listdir(epoch_pictures_path))//2\n",
    "    fig = plt.figure(figsize=(WIDTH*columns, HEIGHT*nb_pictures))\n",
    "    for i in range(nb_pictures):\n",
    "        picture = plt.imread(os.path.join(epoch_pictures_path, get_model_img_name(i, \"picture\")))\n",
    "        cartoon = plt.imread(os.path.join(epoch_pictures_path, get_model_img_name(i, \"cartoon\")))\n",
    "        ax = fig.add_subplot(nb_pictures, columns, 2*i+1)\n",
    "        ax.imshow(picture)\n",
    "        ax.axis(\"off\")\n",
    "        ax = fig.add_subplot(nb_pictures, columns, 2*i+2)\n",
    "        ax.imshow(cartoon)\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(MODEL_ID)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95d434c15d7c1f28b268fe54cfe54716ddab65e34521285ad9829a57e3094f9f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
