{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Cartoon GAN\n",
    "\n",
    "Jupyter notebook version of the ```src.networks.train.py``` file.\n",
    "This file contains all cells to train the model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure drive (only if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "PROJECT_DIRECTORY = \"drive/MyDrive/DeepL\"\n",
    "os.chdir(PROJECT_DIRECTORY)\n",
    "\n",
    "!ls\n",
    "# !pip install -r requirements.txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "\n",
    "if cuda:\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  !nvidia-smi\n",
    "\n",
    "device = \"cuda\" if cuda else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main parameters\n",
    "\n",
    "It is easier to change some parameters in `.ipynb` file instead of `config.py` while using Google colaboratory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_SAVE_PATH = \"\"\n",
    "epochs_train = 50\n",
    "epochs_pretraining = 50\n",
    "lr_generator = 0.001\n",
    "lr_discriminator = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.cartoon_loader import CartoonDatasetLoader\n",
    "from src.dataset.pictures_loader import PicturesDatasetLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import src.networks as networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = networks.Generator()\n",
    "discriminator = networks.Discriminator()\n",
    "vgg19 = networks.VGG19()\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "vgg19.to(device)\n",
    "\n",
    "# to train mode\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "# no training\n",
    "vgg19.eval()\n",
    "\n",
    "print(\"------ Networks -------\")\n",
    "networks.print_network(generator)\n",
    "networks.print_network(discriminator)\n",
    "networks.print_network(vgg19)\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optimizer = optim.Adam(\n",
    "    generator.parameters(), \n",
    "    lr=lr_generator, \n",
    "    betas=(args.beta1, args.beta2)\n",
    ")\n",
    "D_optimizer = optim.Adam(\n",
    "    discriminator.parameters(), \n",
    "    lr=lr_discriminator, \n",
    "    betas=(args.beta1, args.beta2)\n",
    ")\n",
    "G_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer=G_optimizer, \n",
    "    milestones=[epochs // 2, epochs // 4 * 3],\n",
    "    gamma=0.1\n",
    ")\n",
    "D_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer=D_optimizer, \n",
    "    milestones=[epochs // 2, epochs // 4 * 3],\n",
    "    gamma=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_hist = {}\n",
    "pre_train_hist['Recon_loss'] = []\n",
    "pre_train_hist['per_epoch_time'] = []\n",
    "pre_train_hist['total_time'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "for epoch in range(pre_train_epoch):\n",
    "\n",
    "    epoch_start_time = time()\n",
    "    Recon_losses = []\n",
    "    for x, _ in train_loader_src:\n",
    "        x = x.to(device)\n",
    "\n",
    "        # train generator G\n",
    "        G_optimizer.zero_grad()\n",
    "\n",
    "        x_feature = VGG((x + 1) / 2)\n",
    "        G_ = G(x)\n",
    "        G_feature = VGG((G_ + 1) / 2)\n",
    "\n",
    "        Recon_loss = 10 * L1_loss(G_feature, x_feature.detach())\n",
    "        Recon_losses.append(Recon_loss.item())\n",
    "        pre_train_hist['Recon_loss'].append(Recon_loss.item())\n",
    "\n",
    "        Recon_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "    per_epoch_time = time.time() - epoch_start_time\n",
    "    pre_train_hist['per_epoch_time'].append(per_epoch_time)\n",
    "    print('[%d/%d] - time: %.2f, Recon loss: %.3f' % ((epoch + 1), args.pre_train_epoch, per_epoch_time, torch.mean(torch.FloatTensor(Recon_losses))))\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "pre_train_hist['total_time'].append(total_time)\n",
    "\n",
    "\n",
    "with open(os.path.join(args.name + '_results',  'pre_train_hist.pkl'), 'wb') as f:\n",
    "    pickle.dump(pre_train_hist, f)\n",
    "\n",
    "with torch.no_grad():\n",
    "    G.eval()\n",
    "    for n, (x, _) in enumerate(train_loader_src):\n",
    "        x = x.to(device)\n",
    "        G_recon = G(x)\n",
    "        result = torch.cat((x[0], G_recon[0]), 2)\n",
    "        path = os.path.join(args.name + '_results', 'Reconstruction', args.name + '_train_recon_' + str(n + 1) + '.png')\n",
    "        plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "        if n == 4:\n",
    "            break\n",
    "\n",
    "    for n, (x, _) in enumerate(test_loader_src):\n",
    "        x = x.to(device)\n",
    "        G_recon = G(x)\n",
    "        result = torch.cat((x[0], G_recon[0]), 2)\n",
    "        path = os.path.join(args.name + '_results', 'Reconstruction', args.name + '_test_recon_' + str(n + 1) + '.png')\n",
    "        plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "        if n == 4:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8df2d989f7395ed4cefddfbe9e8a345d0860b4821e72f8c21974341c5f0b7bda"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('deepLProject': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
