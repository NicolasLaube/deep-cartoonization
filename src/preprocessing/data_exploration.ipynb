{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el3WP-4fTHFD"
      },
      "source": [
        "# Data exploration\n",
        "\n",
        "The goal of this notebook is to explore data and understand how to filter bad frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liRDcf4RVSZK"
      },
      "outputs": [],
      "source": [
        "LUCA_CARTOONS_PATH = \"../../data/cartoon_frames/Luca\"\n",
        "luca_frames_paths = sorted([os.path.join(LUCA_CARTOONS_PATH, frame) for frame in os.listdir(LUCA_CARTOONS_PATH) if os.path.isfile(os.path.join(LUCA_CARTOONS_PATH, frame))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61aGH7GTjNry"
      },
      "outputs": [],
      "source": [
        "TSLOP_CARTOONS_PATH = \"../../data/cartoon_frames/TheSecretLifeOfPets\"\n",
        "tslop_frames_paths = sorted([os.path.join(TSLOP_CARTOONS_PATH, frame) for frame in os.listdir(TSLOP_CARTOONS_PATH) if os.path.isfile(os.path.join(TSLOP_CARTOONS_PATH, frame))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CARTOONS_DF_PATH = \"../../data/frames_all.csv\"\n",
        "frames_df = pd.read_csv(CARTOONS_DF_PATH, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PICTURES_DF_PATH = \"../../data/pictures_all.csv\"\n",
        "pictures_df = pd.read_csv(PICTURES_DF_PATH, index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explore image size\n",
        "\n",
        "All the images don't have the same size. We must see how they differ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frames_df[[\"width\", \"height\"]].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', pictures_df.shape[0]+1)\n",
        "pictures_df[[\"width\", \"height\"]].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frames_df[\"ratio\"] = frames_df.apply(lambda row : row[\"width\"]/row[\"height\"], axis=1)\n",
        "frames_df[\"ratio\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pictures_df[\"ratio\"] = pictures_df.apply(lambda row : row[\"width\"]/row[\"height\"], axis=1)\n",
        "pictures_df[\"ratio\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resolutions are quite different, and some images seem to be in low resolution.\\\n",
        "As we want a resolution of at least 256 x 256 (like in the original paper), we should discard all images with width or height lower than that.\n",
        "\n",
        "All the frames are in a landscape mode, but a lot of the pictures aren't.\\\n",
        "If we crop the images to match a specific resolution, we shouldn't be worried by these ratios. However, if we only resize the images, we may want to discard images in portrait mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resize vs crop\n",
        "\n",
        "We must see how we should preprocess the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sample_frames_df = frames_df.groupby('movie', group_keys=False).apply(lambda x: x.sample(3))\n",
        "# sample_frames_df[\"movie\"].value_counts()\n",
        "sample_frames_df = frames_df.sample(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for path in sample_frames_df[\"path\"]:\n",
        "    image = Image.open(path)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_pictures_df = pictures_df.sample(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for path in sample_pictures_df[\"path\"]:\n",
        "    image = Image.open(path)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_size = (256, 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we can resize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resize = transforms.Resize(new_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for path in sample_frames_df[\"path\"]:\n",
        "    image = Image.open(path)\n",
        "    image = resize(image)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for path in sample_pictures_df[\"path\"]:\n",
        "    image = Image.open(path)\n",
        "    image = resize(image)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Images are here quite deformed.\n",
        "\n",
        "We can now try to crop them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def crop_center(image): \n",
        "    min_side = min(image.size)\n",
        "    ratio = new_size[1]/new_size[0]\n",
        "    image = transforms.CenterCrop((min_side, int(ratio*min_side)))(image)\n",
        "    return resize(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for path in sample_frames_df[\"path\"]:\n",
        "    image = Image.open(path)\n",
        "    image = crop_center(image)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for path in sample_pictures_df[\"path\"]:\n",
        "    image = Image.open(path)\n",
        "    image = crop_center(image)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This solution seems to be the best one as images aren't deformed here.\\\n",
        "We could even randomly crop the image, to avoid always taking its center."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def crop_random(image): \n",
        "    min_side = min(image.size)\n",
        "    ratio = new_size[1]/new_size[0]\n",
        "    image = transforms.RandomCrop((min_side, int(ratio*min_side)))(image)\n",
        "    return resize(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for path in sample_frames_df[\"path\"]:\n",
        "    image = Image.open(path)\n",
        "    image = crop_random(image)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for path in sample_pictures_df[\"path\"]:\n",
        "    image = Image.open(path)\n",
        "    image = crop_random(image)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjyWFrCmThmh"
      },
      "source": [
        "## Detect text in images\n",
        "\n",
        "We want to remove images with titles or added text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1Hb_yykZHCb"
      },
      "outputs": [],
      "source": [
        "interesting_images_text = [0, 1, 3, 13, 27, 28, 32, 41, 46, 47, 48, 50, 51, ]\n",
        "interesting_paths_text = [luca_frames_paths[i] for i in interesting_images_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9yq5VRxuZleX",
        "outputId": "5c410f04-34aa-458c-9d8a-9351c762d313"
      },
      "outputs": [],
      "source": [
        "for path in interesting_paths_text:\n",
        "  img = mpimg.imread(path)\n",
        "  imgplot = plt.imshow(img)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GLDFQDCgZ8ih",
        "outputId": "f845a25b-2015-4cf9-bae3-b3f1eb27ebdd"
      },
      "outputs": [],
      "source": [
        "mser = cv2.MSER_create()\n",
        "\n",
        "for path in interesting_paths_text:\n",
        "  image = Image.open(path)\n",
        "  img = np.asarray(image)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  regions, _ = mser.detectRegions(gray)\n",
        "  hulls = [cv2.convexHull(p.reshape(-1, 1, 2)) for p in regions]\n",
        "  cv2.polylines(img, hulls, 1, (0, 255, 0))\n",
        "\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XPhVqnrdQIl",
        "outputId": "6cc56d10-4d66-40b9-be5c-3c39d76a110d"
      },
      "outputs": [],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOfb09nNeAb6"
      },
      "source": [
        "The mser method doesn't seem to work.\n",
        "\n",
        "Let's try an OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qc4EpOB8dYQX",
        "outputId": "08909bbc-fc90-4c63-cb12-9c2478645eee"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "\n",
        "for path in interesting_paths_text:\n",
        "  image = Image.open(path)\n",
        "  img = np.asarray(image)\n",
        "  print(pytesseract.image_to_string(img).strip())\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoYd7kWbeL-i"
      },
      "source": [
        "The OCR seems to work pretty well.  \n",
        "We can now try it on all the LUCA images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jva4lI2FeTo3",
        "outputId": "23d4913b-fe72-4c85-8495-1b221e42ba86"
      },
      "outputs": [],
      "source": [
        "img_with_text = []\n",
        "for i, path in enumerate(luca_frames_paths[:500]):\n",
        "  image = Image.open(path)\n",
        "  img = np.asarray(image)\n",
        "  detected_text = pytesseract.image_to_string(img).strip()\n",
        "  if detected_text != \"\":\n",
        "    print(i, \"has text:\")\n",
        "    print(detected_text)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    img_with_text.append(i)\n",
        "img_with_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqCwqQkbjsyg"
      },
      "source": [
        "And some frames from another movie:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hb4JqgQIjqml",
        "outputId": "db370719-3aec-4e70-9f5f-3a3806a5750a"
      },
      "outputs": [],
      "source": [
        "for i, path in enumerate(tslop_frames_paths[:20]):\n",
        "  image = Image.open(path)\n",
        "  img = np.asarray(image)\n",
        "  detected_text = pytesseract.image_to_string(img).strip()\n",
        "  print(detected_text)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knwpmPByfTYn"
      },
      "source": [
        "We see here that images with text are often detected, however the OCR also detects text in images without any.\n",
        "\n",
        "We see that we could use this method to remove images with text, by filtering images in which the OCR detects some real words. This would be a nice filter, even if filtering by hand seems much better, as we could not detect some images with text above and filter some without anything on them (or a sign etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfW96RnOfrBn"
      },
      "source": [
        "## Detect blur\n",
        "\n",
        "We will try now to detect blurry images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VzFMd8eWgCk6",
        "outputId": "abef4c80-0d3b-49e4-ca9a-af72546148d0"
      },
      "outputs": [],
      "source": [
        "for path in tslop_frames_paths[:30]:\n",
        "  image = Image.open(path)\n",
        "  img = np.asarray(image)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  fm = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "  print(\"fm =\", fm)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k6h4uqSpmeAg",
        "outputId": "1e6a26a9-3e9a-4e6a-cda8-55a3e25a24d5"
      },
      "outputs": [],
      "source": [
        "for path in luca_frames_paths[:30]:\n",
        "  image = Image.open(path)\n",
        "  img = np.asarray(image)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  fm = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "  print(\"fm =\", fm)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiSSmx0Bqnpy"
      },
      "source": [
        "The Laplacian method doesn't seem to work well on this kind of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT3p6ZjGqsyZ"
      },
      "outputs": [],
      "source": [
        "def detect_blur_fft(image, size=60):\n",
        "\t# grab the dimensions of the image and use the dimensions to\n",
        "\t# derive the center (x, y)-coordinates\n",
        "  (h, w) = image.shape\n",
        "  (cX, cY) = (int(w / 2.0), int(h / 2.0))\n",
        "  # compute the FFT to find the frequency transform, then shift\n",
        "  # the zero frequency component (i.e., DC component located at\n",
        "  # the top-left corner) to the center where it will be more\n",
        "  # easy to analyze\n",
        "  fft = np.fft.fft2(image)\n",
        "  fftShift = np.fft.fftshift(fft)\n",
        "  # zero-out the center of the FFT shift (i.e., remove low\n",
        "  # frequencies), apply the inverse shift such that the DC\n",
        "  # component once again becomes the top-left, and then apply\n",
        "  # the inverse FFT\n",
        "  fftShift[cY - size:cY + size, cX - size:cX + size] = 0\n",
        "  fftShift = np.fft.ifftshift(fftShift)\n",
        "  recon = np.fft.ifft2(fftShift)\n",
        "  # compute the magnitude spectrum of the reconstructed image,\n",
        "  # then compute the mean of the magnitude values\n",
        "  magnitude = 20 * np.log(np.abs(recon))\n",
        "  mean = np.mean(magnitude)\n",
        "  # the image will be considered \"blurry\" if the mean value of the\n",
        "  # magnitudes is less than the threshold value\n",
        "  return mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "euvC3-NxsdiC",
        "outputId": "5b097a8d-7ee2-4b37-8406-ec9a2dcd8abc"
      },
      "outputs": [],
      "source": [
        "for path in tslop_frames_paths[:30]:\n",
        "  image = Image.open(path)\n",
        "  img = np.asarray(image)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  value = detect_blur_fft(gray)\n",
        "  print(\"val =\", value)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "buAz-gRDtRGP",
        "outputId": "82d85ca2-2713-473b-ca30-9122a57488ac"
      },
      "outputs": [],
      "source": [
        "for path in luca_frames_paths[:30]:\n",
        "  image = Image.open(path)\n",
        "  img = np.asarray(image)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  value = detect_blur_fft(gray)\n",
        "  print(\"val =\", value)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GygHLTjmuEFe"
      },
      "source": [
        "The fft method doesn't seem to work either. We must do that by hand.\n",
        "\n",
        "**Remark:** there are only a few blurry images, maybe it's not important to delete them."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "exploration.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
